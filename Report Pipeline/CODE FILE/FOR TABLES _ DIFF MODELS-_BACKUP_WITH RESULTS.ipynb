{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75acd1e3-691e-4e51-9881-6a77d2a4baaf",
   "metadata": {},
   "source": [
    "<h1>Load the Dataset and Libraries</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c862fc9a-0c6e-4b04-a78c-3a1c3d07fefd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SC_AGE_YEARS</th>\n",
       "      <th>sex_2122</th>\n",
       "      <th>allergies_2122</th>\n",
       "      <th>asthma_2122</th>\n",
       "      <th>headache_2122</th>\n",
       "      <th>anxiety_2122</th>\n",
       "      <th>depress_2122</th>\n",
       "      <th>behavior_2122</th>\n",
       "      <th>GeneticScr_2122</th>\n",
       "      <th>BrainInjTold_2122</th>\n",
       "      <th>...</th>\n",
       "      <th>ChHlthSt_2122</th>\n",
       "      <th>ExBrstFd_2122</th>\n",
       "      <th>DevDelay_2122</th>\n",
       "      <th>learning_2122</th>\n",
       "      <th>autism_2122</th>\n",
       "      <th>BedTime_2122</th>\n",
       "      <th>ACE1more4Com_2122</th>\n",
       "      <th>ACEincome_2122</th>\n",
       "      <th>ACE2more11_2122</th>\n",
       "      <th>ADHD_2122</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SC_AGE_YEARS  sex_2122  allergies_2122  asthma_2122  headache_2122  \\\n",
       "0             5         1             1.0          1.0            1.0   \n",
       "1             8         2             3.0          3.0            1.0   \n",
       "2             5         2             1.0          1.0            1.0   \n",
       "3             6         2             2.0          1.0            1.0   \n",
       "4            17         1             1.0          1.0            1.0   \n",
       "\n",
       "   anxiety_2122  depress_2122  behavior_2122  GeneticScr_2122  \\\n",
       "0           1.0           1.0            1.0              1.0   \n",
       "1           2.0           1.0            1.0              1.0   \n",
       "2           1.0           1.0            1.0              1.0   \n",
       "3           1.0           1.0            1.0              1.0   \n",
       "4           1.0           1.0            1.0              1.0   \n",
       "\n",
       "   BrainInjTold_2122  ...  ChHlthSt_2122  ExBrstFd_2122  DevDelay_2122  \\\n",
       "0                1.0  ...            1.0            1.0            1.0   \n",
       "1                1.0  ...            2.0            4.0            1.0   \n",
       "2                1.0  ...            1.0            1.0            1.0   \n",
       "3                1.0  ...            1.0            4.0            1.0   \n",
       "4                1.0  ...            1.0            4.0            1.0   \n",
       "\n",
       "   learning_2122  autism_2122  BedTime_2122  ACE1more4Com_2122  \\\n",
       "0            1.0          1.0           2.0                1.0   \n",
       "1            1.0          1.0           1.0                1.0   \n",
       "2            1.0          1.0           2.0                1.0   \n",
       "3            1.0          1.0           2.0                1.0   \n",
       "4            1.0          1.0           1.0                1.0   \n",
       "\n",
       "   ACEincome_2122  ACE2more11_2122  ADHD_2122  \n",
       "0             1.0              1.0        0.0  \n",
       "1             2.0              2.0        0.0  \n",
       "2             1.0              2.0        0.0  \n",
       "3             2.0              1.0        0.0  \n",
       "4             1.0              2.0        0.0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments, AutoModelForCausalLM\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('for_LLM_export.csv')\n",
    "\n",
    "# Display the first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc71d13d-d1e9-4405-a54a-32927ab19c01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7f62426-3c01-444f-8caf-dfa40d4e5f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf3e93f9-f3a6-4588-a4e4-5940ba8eecfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SC_AGE_YEARS', 'sex_2122', 'allergies_2122', 'asthma_2122',\n",
       "       'headache_2122', 'anxiety_2122', 'depress_2122', 'behavior_2122',\n",
       "       'GeneticScr_2122', 'BrainInjTold_2122', 'ACE2more6HH_2122',\n",
       "       'famstruct5_2122', 'fruit_2122', 'vegetables_2122', 'Cond2more_2122',\n",
       "       'CSHCNtype_2122', 'ChHlthSt_2122', 'ExBrstFd_2122', 'DevDelay_2122',\n",
       "       'learning_2122', 'autism_2122', 'BedTime_2122', 'ACE1more4Com_2122',\n",
       "       'ACEincome_2122', 'ACE2more11_2122', 'ADHD_2122'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8025631b-47de-4cc7-9745-72f4b81bc74e",
   "metadata": {},
   "source": [
    "<h1>Apply Mappings for Preprocessing</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3ebcebf-6116-4926-9fc6-8963cc1c7265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SC_AGE_YEARS sex_2122                      allergies_2122  \\\n",
      "0             5     Male             Does Not Have Condition   \n",
      "1             8   Female             Currently Has Condition   \n",
      "2             5   Female             Does Not Have Condition   \n",
      "3             6   Female  Ever Told, Does Not Currently Have   \n",
      "4            17     Male             Does Not Have Condition   \n",
      "\n",
      "               asthma_2122            headache_2122  \\\n",
      "0  Does Not Have Condition  Does Not Have Condition   \n",
      "1  Currently Has Condition  Does Not Have Condition   \n",
      "2  Does Not Have Condition  Does Not Have Condition   \n",
      "3  Does Not Have Condition  Does Not Have Condition   \n",
      "4  Does Not Have Condition  Does Not Have Condition   \n",
      "\n",
      "                         anxiety_2122             depress_2122  \\\n",
      "0             Does Not Have Condition  Does Not Have Condition   \n",
      "1  Ever Told, Does Not Currently Have  Does Not Have Condition   \n",
      "2             Does Not Have Condition  Does Not Have Condition   \n",
      "3             Does Not Have Condition  Does Not Have Condition   \n",
      "4             Does Not Have Condition  Does Not Have Condition   \n",
      "\n",
      "             behavior_2122      GeneticScr_2122  \\\n",
      "0  Does Not Have Condition  Never Had Condition   \n",
      "1  Does Not Have Condition  Never Had Condition   \n",
      "2  Does Not Have Condition  Never Had Condition   \n",
      "3  Does Not Have Condition  Never Had Condition   \n",
      "4  Does Not Have Condition  Never Had Condition   \n",
      "\n",
      "                BrainInjTold_2122  ... ChHlthSt_2122         ExBrstFd_2122  \\\n",
      "0  Never Thought Child Has Injury  ...     Excellent                 Never   \n",
      "1  Never Thought Child Has Injury  ...          Good  6 Months Exclusively   \n",
      "2  Never Thought Child Has Injury  ...     Excellent                 Never   \n",
      "3  Never Thought Child Has Injury  ...     Excellent  6 Months Exclusively   \n",
      "4  Never Thought Child Has Injury  ...     Excellent  6 Months Exclusively   \n",
      "\n",
      "             DevDelay_2122            learning_2122              autism_2122  \\\n",
      "0  Does Not Have Condition  Does Not Have Condition  Does Not Have Condition   \n",
      "1  Does Not Have Condition  Does Not Have Condition  Does Not Have Condition   \n",
      "2  Does Not Have Condition  Does Not Have Condition  Does Not Have Condition   \n",
      "3  Does Not Have Condition  Does Not Have Condition  Does Not Have Condition   \n",
      "4  Does Not Have Condition  Does Not Have Condition  Does Not Have Condition   \n",
      "\n",
      "  BedTime_2122 ACE1more4Com_2122 ACEincome_2122 ACE2more11_2122  \\\n",
      "0      Usually           No Aces        No Aces         No Aces   \n",
      "1       Always           No Aces         Rarely      Single Ace   \n",
      "2      Usually           No Aces        No Aces      Single Ace   \n",
      "3      Usually           No Aces         Rarely         No Aces   \n",
      "4       Always           No Aces        No Aces      Single Ace   \n",
      "\n",
      "            ADHD_2122  \n",
      "0  Does Not Have ADHD  \n",
      "1  Does Not Have ADHD  \n",
      "2  Does Not Have ADHD  \n",
      "3  Does Not Have ADHD  \n",
      "4  Does Not Have ADHD  \n",
      "\n",
      "[5 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assume df1 is already loaded, e.g., via:\n",
    "# df1 = pd.read_csv('your_file.csv')\n",
    "\n",
    "# List of columns to convert to numeric (based on your mapping columns)\n",
    "columns_to_convert = [\n",
    "    'sex_2122', 'allergies_2122', 'asthma_2122', 'headache_2122', 'anxiety_2122', \n",
    "    'depress_2122', 'behavior_2122', 'GeneticScr_2122', 'BrainInjTold_2122', 'ACE2more6HH_2122',\n",
    "    'famstruct5_2122', 'fruit_2122', 'vegetables_2122', 'Cond2more_2122', 'CSHCNtype_2122',\n",
    "    'ChHlthSt_2122', 'ExBrstFd_2122', 'DevDelay_2122', 'learning_2122', 'autism_2122', \n",
    "    'BedTime_2122', 'ACE1more4Com_2122', 'ACEincome_2122', 'ACE2more11_2122', 'ADHD_2122'\n",
    "]\n",
    "\n",
    "# Convert these columns to numeric (non-numeric values become NaN)\n",
    "for col in columns_to_convert:\n",
    "    df1[col] = pd.to_numeric(df1[col], errors='coerce')\n",
    "\n",
    "# Provided mapping dictionary (maps descriptive string to integer)\n",
    "mappings = {\n",
    "    'sex_2122': {'Male': 1, 'Female': 2},\n",
    "    'allergies_2122': {\n",
    "        'Does Not Have Condition': 1, \n",
    "        'Ever Told, Does Not Currently Have': 2, \n",
    "        'Currently Has Condition': 3\n",
    "    },\n",
    "    'asthma_2122': {\n",
    "        'Does Not Have Condition': 1, \n",
    "        'Ever Told, Does Not Currently Have': 2, \n",
    "        'Currently Has Condition': 3\n",
    "    },\n",
    "    'headache_2122': {\n",
    "        'Does Not Have Condition': 1, \n",
    "        'Ever Told, Does Not Currently Have': 2, \n",
    "        'Currently Has Condition': 3\n",
    "    },\n",
    "    'anxiety_2122': {\n",
    "        'Does Not Have Condition': 1, \n",
    "        'Ever Told, Does Not Currently Have': 2, \n",
    "        'Currently Has Condition': 3\n",
    "    },\n",
    "    'depress_2122': {\n",
    "        'Does Not Have Condition': 1, \n",
    "        'Ever Told, Does Not Currently Have': 2, \n",
    "        'Currently Has Condition': 3\n",
    "    },\n",
    "    'behavior_2122': {\n",
    "        'Does Not Have Condition': 1, \n",
    "        'Ever Told, Does Not Currently Have': 2, \n",
    "        'Currently Has Condition': 3\n",
    "    },\n",
    "    'GeneticScr_2122': {\n",
    "        'Never Had Condition': 1, \n",
    "        'Ever Told, Not Identified By Test': 2, \n",
    "        'Ever Told, Identified By Test': 3\n",
    "    },\n",
    "    'BrainInjTold_2122': {\n",
    "        'Never Thought Child Has Injury': 1, \n",
    "        'Ever Thought, Not Confirmed': 2, \n",
    "        'Ever Had Injury Confirmed By Doctor': 3\n",
    "    },\n",
    "    'ACE2more6HH_2122': {\n",
    "        'No Aces': 1, \n",
    "        '1 Ace': 2, \n",
    "        '2 Or More Aces': 3\n",
    "    },\n",
    "    'famstruct5_2122': {\n",
    "        'Two Parents, Married': 1, \n",
    "        'Two Parents, Not Married': 2, \n",
    "        'Single Parent': 3, \n",
    "        'Grandparent Household': 4, \n",
    "        'Other Family Type': 5\n",
    "    },\n",
    "    'fruit_2122': {\n",
    "        'Never': 1, \n",
    "        'Rarely': 2, \n",
    "        'Sometimes': 3, \n",
    "        'Regularly': 4, \n",
    "        'Often': 5, \n",
    "        'Always': 6\n",
    "    },\n",
    "    'vegetables_2122': {\n",
    "        'Never': 1, \n",
    "        'Rarely': 2, \n",
    "        'Sometimes': 3, \n",
    "        'Regularly': 4, \n",
    "        'Often': 5, \n",
    "        'Always': 6\n",
    "    },\n",
    "    'Cond2more_2122': {\n",
    "        'None': 1, \n",
    "        'One Condition': 2, \n",
    "        'Multiple Conditions': 3\n",
    "    },\n",
    "    'CSHCNtype_2122': {\n",
    "        'None': 0, \n",
    "        'Functional Limitations': 1, \n",
    "        'Prescription Medication Only': 2, \n",
    "        'Above-Routine Use Of Services': 3, \n",
    "        'Medication And Above-Routine Services': 4\n",
    "    },\n",
    "    'ChHlthSt_2122': {\n",
    "        'Excellent': 1, \n",
    "        'Good': 2, \n",
    "        'Fair Or Poor': 3\n",
    "    },\n",
    "    'ExBrstFd_2122': {\n",
    "        'Never': 1, \n",
    "        'Less Than 6 Months': 2, \n",
    "        '6 Months Regular Not Exclusively': 3, \n",
    "        '6 Months Exclusively': 4\n",
    "    },\n",
    "    'DevDelay_2122': {\n",
    "        'Does Not Have Condition': 1, \n",
    "        'Ever Told, Does Not Currently Have': 2, \n",
    "        'Currently Has Condition': 3\n",
    "    },\n",
    "    'learning_2122': {\n",
    "        'Does Not Have Condition': 1, \n",
    "        'Ever Told, Does Not Currently Have': 2, \n",
    "        'Currently Has Condition': 3\n",
    "    },\n",
    "    'autism_2122': {\n",
    "        'Does Not Have Condition': 1, \n",
    "        'Ever Told, Does Not Currently Have': 2, \n",
    "        'Currently Has Condition': 3\n",
    "    },\n",
    "    'BedTime_2122': {\n",
    "        'Always': 1, \n",
    "        'Usually': 2, \n",
    "        'Sometimes': 3, \n",
    "        'Rarely Or Never': 4\n",
    "    },\n",
    "    'ACE1more4Com_2122': {\n",
    "        'No Aces': 1, \n",
    "        '1 Or More Aces': 2\n",
    "    },\n",
    "    'ACEincome_2122': {\n",
    "        'No Aces': 1, \n",
    "        'Rarely': 2, \n",
    "        'Often': 3, \n",
    "        'Very Often': 4\n",
    "    },\n",
    "    'ACE2more11_2122': {\n",
    "        'No Aces': 1, \n",
    "        'Single Ace': 2, \n",
    "        'Multiple Aces': 3\n",
    "    },\n",
    "    'ADHD_2122': {\n",
    "        'Does Not Have ADHD': 0, \n",
    "        'Currently Has ADHD': 1\n",
    "    },\n",
    "}\n",
    "\n",
    "# Invert each mapping so that integer codes become keys and descriptive strings become values.\n",
    "inverted_mappings = {col: {v: k for k, v in mapping.items()} for col, mapping in mappings.items()}\n",
    "\n",
    "# Apply the inverted mappings to the corresponding columns in df1\n",
    "for col, inv_map in inverted_mappings.items():\n",
    "    if col in df1.columns:\n",
    "        df1[col] = df1[col].map(inv_map)\n",
    "\n",
    "# Optionally, fill any unmapped or missing values with 'Unknown'\n",
    "df1.fillna('Unknown', inplace=True)\n",
    "\n",
    "# Display the first few rows of the decoded DataFrame\n",
    "print(df1.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "366fcc73-bed4-429d-9827-5d08f24d229f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SC_AGE_YEARS</th>\n",
       "      <th>sex_2122</th>\n",
       "      <th>allergies_2122</th>\n",
       "      <th>asthma_2122</th>\n",
       "      <th>headache_2122</th>\n",
       "      <th>anxiety_2122</th>\n",
       "      <th>depress_2122</th>\n",
       "      <th>behavior_2122</th>\n",
       "      <th>GeneticScr_2122</th>\n",
       "      <th>BrainInjTold_2122</th>\n",
       "      <th>...</th>\n",
       "      <th>ChHlthSt_2122</th>\n",
       "      <th>ExBrstFd_2122</th>\n",
       "      <th>DevDelay_2122</th>\n",
       "      <th>learning_2122</th>\n",
       "      <th>autism_2122</th>\n",
       "      <th>BedTime_2122</th>\n",
       "      <th>ACE1more4Com_2122</th>\n",
       "      <th>ACEincome_2122</th>\n",
       "      <th>ACE2more11_2122</th>\n",
       "      <th>ADHD_2122</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Male</td>\n",
       "      <td>Does Not Have Condition</td>\n",
       "      <td>Does Not Have Condition</td>\n",
       "      <td>Does Not Have Condition</td>\n",
       "      <td>Does Not Have Condition</td>\n",
       "      <td>Does Not Have Condition</td>\n",
       "      <td>Does Not Have Condition</td>\n",
       "      <td>Never Had Condition</td>\n",
       "      <td>Never Thought Child Has Injury</td>\n",
       "      <td>...</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>Never</td>\n",
       "      <td>Does Not Have Condition</td>\n",
       "      <td>Does Not Have Condition</td>\n",
       "      <td>Does Not Have Condition</td>\n",
       "      <td>Usually</td>\n",
       "      <td>No Aces</td>\n",
       "      <td>No Aces</td>\n",
       "      <td>No Aces</td>\n",
       "      <td>Does Not Have ADHD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>Female</td>\n",
       "      <td>Currently Has Condition</td>\n",
       "      <td>Currently Has Condition</td>\n",
       "      <td>Does Not Have Condition</td>\n",
       "      <td>Ever Told, Does Not Currently Have</td>\n",
       "      <td>Does Not Have Condition</td>\n",
       "      <td>Does Not Have Condition</td>\n",
       "      <td>Never Had Condition</td>\n",
       "      <td>Never Thought Child Has Injury</td>\n",
       "      <td>...</td>\n",
       "      <td>Good</td>\n",
       "      <td>6 Months Exclusively</td>\n",
       "      <td>Does Not Have Condition</td>\n",
       "      <td>Does Not Have Condition</td>\n",
       "      <td>Does Not Have Condition</td>\n",
       "      <td>Always</td>\n",
       "      <td>No Aces</td>\n",
       "      <td>Rarely</td>\n",
       "      <td>Single Ace</td>\n",
       "      <td>Does Not Have ADHD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Female</td>\n",
       "      <td>Does Not Have Condition</td>\n",
       "      <td>Does Not Have Condition</td>\n",
       "      <td>Does Not Have Condition</td>\n",
       "      <td>Does Not Have Condition</td>\n",
       "      <td>Does Not Have Condition</td>\n",
       "      <td>Does Not Have Condition</td>\n",
       "      <td>Never Had Condition</td>\n",
       "      <td>Never Thought Child Has Injury</td>\n",
       "      <td>...</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>Never</td>\n",
       "      <td>Does Not Have Condition</td>\n",
       "      <td>Does Not Have Condition</td>\n",
       "      <td>Does Not Have Condition</td>\n",
       "      <td>Usually</td>\n",
       "      <td>No Aces</td>\n",
       "      <td>No Aces</td>\n",
       "      <td>Single Ace</td>\n",
       "      <td>Does Not Have ADHD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>Female</td>\n",
       "      <td>Ever Told, Does Not Currently Have</td>\n",
       "      <td>Does Not Have Condition</td>\n",
       "      <td>Does Not Have Condition</td>\n",
       "      <td>Does Not Have Condition</td>\n",
       "      <td>Does Not Have Condition</td>\n",
       "      <td>Does Not Have Condition</td>\n",
       "      <td>Never Had Condition</td>\n",
       "      <td>Never Thought Child Has Injury</td>\n",
       "      <td>...</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>6 Months Exclusively</td>\n",
       "      <td>Does Not Have Condition</td>\n",
       "      <td>Does Not Have Condition</td>\n",
       "      <td>Does Not Have Condition</td>\n",
       "      <td>Usually</td>\n",
       "      <td>No Aces</td>\n",
       "      <td>Rarely</td>\n",
       "      <td>No Aces</td>\n",
       "      <td>Does Not Have ADHD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>Male</td>\n",
       "      <td>Does Not Have Condition</td>\n",
       "      <td>Does Not Have Condition</td>\n",
       "      <td>Does Not Have Condition</td>\n",
       "      <td>Does Not Have Condition</td>\n",
       "      <td>Does Not Have Condition</td>\n",
       "      <td>Does Not Have Condition</td>\n",
       "      <td>Never Had Condition</td>\n",
       "      <td>Never Thought Child Has Injury</td>\n",
       "      <td>...</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>6 Months Exclusively</td>\n",
       "      <td>Does Not Have Condition</td>\n",
       "      <td>Does Not Have Condition</td>\n",
       "      <td>Does Not Have Condition</td>\n",
       "      <td>Always</td>\n",
       "      <td>No Aces</td>\n",
       "      <td>No Aces</td>\n",
       "      <td>Single Ace</td>\n",
       "      <td>Does Not Have ADHD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SC_AGE_YEARS sex_2122                      allergies_2122  \\\n",
       "0             5     Male             Does Not Have Condition   \n",
       "1             8   Female             Currently Has Condition   \n",
       "2             5   Female             Does Not Have Condition   \n",
       "3             6   Female  Ever Told, Does Not Currently Have   \n",
       "4            17     Male             Does Not Have Condition   \n",
       "\n",
       "               asthma_2122            headache_2122  \\\n",
       "0  Does Not Have Condition  Does Not Have Condition   \n",
       "1  Currently Has Condition  Does Not Have Condition   \n",
       "2  Does Not Have Condition  Does Not Have Condition   \n",
       "3  Does Not Have Condition  Does Not Have Condition   \n",
       "4  Does Not Have Condition  Does Not Have Condition   \n",
       "\n",
       "                         anxiety_2122             depress_2122  \\\n",
       "0             Does Not Have Condition  Does Not Have Condition   \n",
       "1  Ever Told, Does Not Currently Have  Does Not Have Condition   \n",
       "2             Does Not Have Condition  Does Not Have Condition   \n",
       "3             Does Not Have Condition  Does Not Have Condition   \n",
       "4             Does Not Have Condition  Does Not Have Condition   \n",
       "\n",
       "             behavior_2122      GeneticScr_2122  \\\n",
       "0  Does Not Have Condition  Never Had Condition   \n",
       "1  Does Not Have Condition  Never Had Condition   \n",
       "2  Does Not Have Condition  Never Had Condition   \n",
       "3  Does Not Have Condition  Never Had Condition   \n",
       "4  Does Not Have Condition  Never Had Condition   \n",
       "\n",
       "                BrainInjTold_2122  ... ChHlthSt_2122         ExBrstFd_2122  \\\n",
       "0  Never Thought Child Has Injury  ...     Excellent                 Never   \n",
       "1  Never Thought Child Has Injury  ...          Good  6 Months Exclusively   \n",
       "2  Never Thought Child Has Injury  ...     Excellent                 Never   \n",
       "3  Never Thought Child Has Injury  ...     Excellent  6 Months Exclusively   \n",
       "4  Never Thought Child Has Injury  ...     Excellent  6 Months Exclusively   \n",
       "\n",
       "             DevDelay_2122            learning_2122              autism_2122  \\\n",
       "0  Does Not Have Condition  Does Not Have Condition  Does Not Have Condition   \n",
       "1  Does Not Have Condition  Does Not Have Condition  Does Not Have Condition   \n",
       "2  Does Not Have Condition  Does Not Have Condition  Does Not Have Condition   \n",
       "3  Does Not Have Condition  Does Not Have Condition  Does Not Have Condition   \n",
       "4  Does Not Have Condition  Does Not Have Condition  Does Not Have Condition   \n",
       "\n",
       "  BedTime_2122 ACE1more4Com_2122 ACEincome_2122 ACE2more11_2122  \\\n",
       "0      Usually           No Aces        No Aces         No Aces   \n",
       "1       Always           No Aces         Rarely      Single Ace   \n",
       "2      Usually           No Aces        No Aces      Single Ace   \n",
       "3      Usually           No Aces         Rarely         No Aces   \n",
       "4       Always           No Aces        No Aces      Single Ace   \n",
       "\n",
       "            ADHD_2122  \n",
       "0  Does Not Have ADHD  \n",
       "1  Does Not Have ADHD  \n",
       "2  Does Not Have ADHD  \n",
       "3  Does Not Have ADHD  \n",
       "4  Does Not Have ADHD  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e73584-9d8d-4910-af15-53e8b727589e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9941f6-11d5-46c6-9c9d-1feb3b7e2caf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "040b2f1e-512a-49de-ba70-07ae917ba36f",
   "metadata": {},
   "source": [
    "<h1> EDA</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c38311-63e7-4d6f-95e7-3d82a86c7d61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e195b9-6023-495a-a97a-630b71c7a3c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4b5701-5fda-4c83-9c7d-b1dc2da0d0fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5c6aca-0f22-4a59-8b51-e7e4e9aedd94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8be6d1d-d0ce-47a9-b692-0dfc26172830",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bfcd2571-db91-4619-9fac-9f3263c7858d",
   "metadata": {},
   "source": [
    "<h1>Train Test Split</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d90312c5-60d5-453c-a3ec-376f501264ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 53332\n",
      "Number of test samples: 13334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define a label mapping for ADHD\n",
    "label_mapping = {\n",
    "    \"Does Not Have ADHD\": 0,\n",
    "    \"Currently Has ADHD\": 1\n",
    "}\n",
    "\n",
    "# Filter df1 to keep only rows with valid ADHD labels\n",
    "df1 = df1[df1[\"ADHD_2122\"].isin(label_mapping.keys())]\n",
    "\n",
    "# Convert the target labels from strings to integers\n",
    "y = df1[\"ADHD_2122\"].map(label_mapping)\n",
    "\n",
    "# Use all other columns (except ADHD_2122) as features\n",
    "X = df1.drop(\"ADHD_2122\", axis=1)\n",
    "\n",
    "# For text-based input, combine all features into a single string per sample\n",
    "X_text = X.astype(str).apply(lambda row: \" \".join(row), axis=1)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_text, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Number of training samples:\", len(X_train))\n",
    "print(\"Number of test samples:\", len(X_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6909a9-d0c3-475d-b257-ac414f5e1419",
   "metadata": {},
   "source": [
    "<h1>Create a Custom Dataset Class</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5ff6833-f3db-4127-97bd-90eeeb53516b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels.iloc[idx] if hasattr(self.labels, 'iloc') else self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c95da6-d0e6-4233-abe1-479a10deb458",
   "metadata": {},
   "source": [
    "<h1>Tokenize the Data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6592443f-b633-4c1e-9081-30712b0a3da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Choose a model checkpoint (this can be varied later, e.g., \"bert-base-uncased\", \"distilbert-base-uncased\", etc.)\n",
    "model_checkpoint = \"bert-base-uncased\"\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "# Tokenize the training and testing text data\n",
    "train_encodings = tokenizer(list(X_train), truncation=True, padding=True, max_length=128)\n",
    "test_encodings = tokenizer(list(X_test), truncation=True, padding=True, max_length=128)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfceb4a-28c9-437c-8b70-d8c7837d932c",
   "metadata": {},
   "source": [
    "<h1>Create a Custom PyTorch Dataset</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2fd638ae-9398-447b-b1d9-db8952ff2f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        # Ensure labels are stored as a list of integers\n",
    "        self.labels = list(labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Convert each item in the encoding to a tensor\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        # Convert the label to a tensor (now an integer)\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = CustomDataset(train_encodings, y_train)\n",
    "test_dataset = CustomDataset(test_encodings, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c93ef9-5022-4034-b02b-abc9698a37c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "df34bf44-4b90-4afe-9f6d-6a0a7f4f1402",
   "metadata": {},
   "source": [
    "<h1>Set Up the Model, Training Arguments, and Trainer</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8433a98-a5ef-4989-b1ac-c7a41e17ecc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\User\\anaconda3\\envs\\llm_env\\lib\\site-packages\\transformers\\training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import os\n",
    "\n",
    "# Define a function to compute evaluation metrics\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    acc = accuracy_score(labels, predictions)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='weighted')\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }\n",
    "\n",
    "# Load the pre-trained model (assuming a classification task with 2 labels)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=2)\n",
    "\n",
    "# Define the base directory for saving models, logs, and results\n",
    "base_dir = r\"E:\\LLMS_ALL MODELS\"\n",
    "\n",
    "# Set up training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=os.path.join(base_dir, 'results'),    # All models will be saved here\n",
    "    num_train_epochs=3,                              # Number of training epochs\n",
    "    per_device_train_batch_size=16,                  # Training batch size\n",
    "    per_device_eval_batch_size=64,                   # Evaluation batch size\n",
    "    evaluation_strategy=\"epoch\",                     # Evaluate at the end of each epoch\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=os.path.join(base_dir, 'logs'),      # Directory for logging\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\"\n",
    ")\n",
    "\n",
    "# Create PyTorch datasets from your encodings\n",
    "train_dataset = CustomDataset(train_encodings, y_train)\n",
    "test_dataset = CustomDataset(test_encodings, y_test)\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fa1067-add6-4f1e-804d-0b7fcaee2a60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "71860be6-4201-4943-9ffe-38bcaaad8b9b",
   "metadata": {},
   "source": [
    "<h1>Loop Over Multiple Pre-trained Models for Training & Evaluation</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "facba904-584e-4fa0-aeb9-ce279a227d78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing model: BERT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10002' max='10002' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10002/10002 30:30, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.173000</td>\n",
       "      <td>0.247440</td>\n",
       "      <td>0.871456</td>\n",
       "      <td>0.915202</td>\n",
       "      <td>0.871456</td>\n",
       "      <td>0.886181</td>\n",
       "      <td>0.910916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.292200</td>\n",
       "      <td>0.235159</td>\n",
       "      <td>0.891930</td>\n",
       "      <td>0.795540</td>\n",
       "      <td>0.891930</td>\n",
       "      <td>0.840982</td>\n",
       "      <td>0.817046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.179000</td>\n",
       "      <td>0.237306</td>\n",
       "      <td>0.891930</td>\n",
       "      <td>0.795540</td>\n",
       "      <td>0.891930</td>\n",
       "      <td>0.840982</td>\n",
       "      <td>0.918995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\llm_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\User\\anaconda3\\envs\\llm_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='209' max='209' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [209/209 00:36]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for BERT: {'eval_loss': 0.24744021892547607, 'eval_accuracy': 0.871456427178641, 'eval_precision': 0.9152022297681924, 'eval_recall': 0.871456427178641, 'eval_f1': 0.8861814585122536, 'eval_auc': 0.9109164629115745, 'eval_runtime': 36.4737, 'eval_samples_per_second': 365.578, 'eval_steps_per_second': 5.73, 'epoch': 3.0}\n",
      "\n",
      "Processing model: DistilBERT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\llm_env\\lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\User\\.cache\\huggingface\\hub\\models--distilbert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\User\\anaconda3\\envs\\llm_env\\lib\\site-packages\\transformers\\training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10002' max='10002' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10002/10002 16:09, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.172900</td>\n",
       "      <td>0.158218</td>\n",
       "      <td>0.927779</td>\n",
       "      <td>0.932010</td>\n",
       "      <td>0.927779</td>\n",
       "      <td>0.929597</td>\n",
       "      <td>0.960178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.152300</td>\n",
       "      <td>0.162200</td>\n",
       "      <td>0.933403</td>\n",
       "      <td>0.927765</td>\n",
       "      <td>0.933403</td>\n",
       "      <td>0.927771</td>\n",
       "      <td>0.964948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.157100</td>\n",
       "      <td>0.142216</td>\n",
       "      <td>0.934453</td>\n",
       "      <td>0.932290</td>\n",
       "      <td>0.934453</td>\n",
       "      <td>0.933216</td>\n",
       "      <td>0.968324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='209' max='209' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [209/209 00:19]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for DistilBERT: {'eval_loss': 0.1422160267829895, 'eval_accuracy': 0.9344532773361331, 'eval_precision': 0.9322902790479016, 'eval_recall': 0.9344532773361331, 'eval_f1': 0.9332159079764323, 'eval_auc': 0.9683241087996468, 'eval_runtime': 19.2482, 'eval_samples_per_second': 692.74, 'eval_steps_per_second': 10.858, 'epoch': 3.0}\n",
      "\n",
      "Processing model: ClinicalBERT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\llm_env\\lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\User\\.cache\\huggingface\\hub\\models--emilyalsentzer--Bio_ClinicalBERT. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at emilyalsentzer/Bio_ClinicalBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\User\\anaconda3\\envs\\llm_env\\lib\\site-packages\\transformers\\training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10002' max='10002' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10002/10002 32:30, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.383900</td>\n",
       "      <td>0.342826</td>\n",
       "      <td>0.892680</td>\n",
       "      <td>0.904207</td>\n",
       "      <td>0.892680</td>\n",
       "      <td>0.842805</td>\n",
       "      <td>0.291205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.373500</td>\n",
       "      <td>0.343133</td>\n",
       "      <td>0.891930</td>\n",
       "      <td>0.795540</td>\n",
       "      <td>0.891930</td>\n",
       "      <td>0.840982</td>\n",
       "      <td>0.893119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.296100</td>\n",
       "      <td>0.341232</td>\n",
       "      <td>0.891930</td>\n",
       "      <td>0.795540</td>\n",
       "      <td>0.891930</td>\n",
       "      <td>0.840982</td>\n",
       "      <td>0.912652</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\llm_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\User\\anaconda3\\envs\\llm_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='209' max='209' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [209/209 00:35]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for ClinicalBERT: {'eval_loss': 0.34282612800598145, 'eval_accuracy': 0.8926803659817009, 'eval_precision': 0.9042065140063321, 'eval_recall': 0.8926803659817009, 'eval_f1': 0.8428052311254455, 'eval_auc': 0.291205213874139, 'eval_runtime': 36.0431, 'eval_samples_per_second': 369.946, 'eval_steps_per_second': 5.799, 'epoch': 3.0}\n",
      "\n",
      "Processing model: BioBERT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\llm_env\\lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\User\\.cache\\huggingface\\hub\\models--dmis-lab--biobert-v1.1. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dmis-lab/biobert-v1.1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\User\\anaconda3\\envs\\llm_env\\lib\\site-packages\\transformers\\training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10002' max='10002' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10002/10002 35:18, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.381100</td>\n",
       "      <td>0.344358</td>\n",
       "      <td>0.891930</td>\n",
       "      <td>0.795540</td>\n",
       "      <td>0.891930</td>\n",
       "      <td>0.840982</td>\n",
       "      <td>0.731068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.330400</td>\n",
       "      <td>0.252445</td>\n",
       "      <td>0.891930</td>\n",
       "      <td>0.795540</td>\n",
       "      <td>0.891930</td>\n",
       "      <td>0.840982</td>\n",
       "      <td>0.901861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.176600</td>\n",
       "      <td>0.236467</td>\n",
       "      <td>0.891930</td>\n",
       "      <td>0.795540</td>\n",
       "      <td>0.891930</td>\n",
       "      <td>0.840982</td>\n",
       "      <td>0.909164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\llm_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\User\\anaconda3\\envs\\llm_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\User\\anaconda3\\envs\\llm_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='209' max='209' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [209/209 00:41]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\llm_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for BioBERT: {'eval_loss': 0.3443581759929657, 'eval_accuracy': 0.891930403479826, 'eval_precision': 0.7955398446516853, 'eval_recall': 0.891930403479826, 'eval_f1': 0.8409821452083538, 'eval_auc': 0.7310684274592096, 'eval_runtime': 42.166, 'eval_samples_per_second': 316.227, 'eval_steps_per_second': 4.957, 'epoch': 3.0}\n",
      "\n",
      "Processing model: ALBERT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\llm_env\\lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\User\\.cache\\huggingface\\hub\\models--albert-base-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\User\\anaconda3\\envs\\llm_env\\lib\\site-packages\\transformers\\training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10002' max='10002' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10002/10002 32:09, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.187400</td>\n",
       "      <td>0.240086</td>\n",
       "      <td>0.871381</td>\n",
       "      <td>0.915181</td>\n",
       "      <td>0.871381</td>\n",
       "      <td>0.886124</td>\n",
       "      <td>0.905118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.245100</td>\n",
       "      <td>0.224050</td>\n",
       "      <td>0.923879</td>\n",
       "      <td>0.917570</td>\n",
       "      <td>0.923879</td>\n",
       "      <td>0.919432</td>\n",
       "      <td>0.911040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.208100</td>\n",
       "      <td>0.182868</td>\n",
       "      <td>0.927029</td>\n",
       "      <td>0.922087</td>\n",
       "      <td>0.927029</td>\n",
       "      <td>0.923764</td>\n",
       "      <td>0.950122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='209' max='209' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [209/209 00:46]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for ALBERT: {'eval_loss': 0.18286828696727753, 'eval_accuracy': 0.9270286485675716, 'eval_precision': 0.9220874055441293, 'eval_recall': 0.9270286485675716, 'eval_f1': 0.9237637642894898, 'eval_auc': 0.9501220196532663, 'eval_runtime': 46.2472, 'eval_samples_per_second': 288.32, 'eval_steps_per_second': 4.519, 'epoch': 3.0}\n",
      "\n",
      "Final comparison of models:\n",
      "BERT: {'eval_loss': 0.24744021892547607, 'eval_accuracy': 0.871456427178641, 'eval_precision': 0.9152022297681924, 'eval_recall': 0.871456427178641, 'eval_f1': 0.8861814585122536, 'eval_auc': 0.9109164629115745, 'eval_runtime': 36.4737, 'eval_samples_per_second': 365.578, 'eval_steps_per_second': 5.73, 'epoch': 3.0}\n",
      "DistilBERT: {'eval_loss': 0.1422160267829895, 'eval_accuracy': 0.9344532773361331, 'eval_precision': 0.9322902790479016, 'eval_recall': 0.9344532773361331, 'eval_f1': 0.9332159079764323, 'eval_auc': 0.9683241087996468, 'eval_runtime': 19.2482, 'eval_samples_per_second': 692.74, 'eval_steps_per_second': 10.858, 'epoch': 3.0}\n",
      "ClinicalBERT: {'eval_loss': 0.34282612800598145, 'eval_accuracy': 0.8926803659817009, 'eval_precision': 0.9042065140063321, 'eval_recall': 0.8926803659817009, 'eval_f1': 0.8428052311254455, 'eval_auc': 0.291205213874139, 'eval_runtime': 36.0431, 'eval_samples_per_second': 369.946, 'eval_steps_per_second': 5.799, 'epoch': 3.0}\n",
      "BioBERT: {'eval_loss': 0.3443581759929657, 'eval_accuracy': 0.891930403479826, 'eval_precision': 0.7955398446516853, 'eval_recall': 0.891930403479826, 'eval_f1': 0.8409821452083538, 'eval_auc': 0.7310684274592096, 'eval_runtime': 42.166, 'eval_samples_per_second': 316.227, 'eval_steps_per_second': 4.957, 'epoch': 3.0}\n",
      "ALBERT: {'eval_loss': 0.18286828696727753, 'eval_accuracy': 0.9270286485675716, 'eval_precision': 0.9220874055441293, 'eval_recall': 0.9270286485675716, 'eval_f1': 0.9237637642894898, 'eval_auc': 0.9501220196532663, 'eval_runtime': 46.2472, 'eval_samples_per_second': 288.32, 'eval_steps_per_second': 4.519, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score\n",
    "\n",
    "# Define the base directory for saving models, logs, and results\n",
    "base_dir = r\"E:\\LLMS_ALL MODELS\"\n",
    "\n",
    "# Define a dictionary with model names and their corresponding checkpoints\n",
    "model_dict = {\n",
    "    \"BERT\": \"bert-base-uncased\",\n",
    "    \"DistilBERT\": \"distilbert-base-uncased\",\n",
    "    \"ClinicalBERT\": \"emilyalsentzer/Bio_ClinicalBERT\",\n",
    "    \"BioBERT\": \"dmis-lab/biobert-v1.1\",\n",
    "    \"ALBERT\": \"albert-base-v2\"\n",
    "    # Add other models as needed\n",
    "}\n",
    "\n",
    "# Define a function to compute evaluation metrics: accuracy, precision, recall, F1, and AUC\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    \n",
    "    # Compute accuracy, precision, recall, and F1\n",
    "    acc = accuracy_score(labels, predictions)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='weighted')\n",
    "    \n",
    "    # Compute probabilities using softmax for AUC calculation\n",
    "    probabilities = np.exp(logits) / np.sum(np.exp(logits), axis=-1, keepdims=True)\n",
    "    prob_positive = probabilities[:, 1]  # probability of class '1'\n",
    "    try:\n",
    "        auc = roc_auc_score(labels, prob_positive)\n",
    "    except ValueError:\n",
    "        auc = 0.0\n",
    "    \n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'auc': auc\n",
    "    }\n",
    "\n",
    "results_dict = {}\n",
    "\n",
    "for model_name, model_checkpoint in model_dict.items():\n",
    "    print(f\"\\nProcessing model: {model_name}\")\n",
    "    \n",
    "    # 1. Load the tokenizer and tokenize the data\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "    train_encodings = tokenizer(list(X_train), truncation=True, padding=True, max_length=128)\n",
    "    test_encodings = tokenizer(list(X_test), truncation=True, padding=True, max_length=128)\n",
    "    \n",
    "    # Create datasets for the current model\n",
    "    train_dataset = CustomDataset(train_encodings, y_train)\n",
    "    test_dataset = CustomDataset(test_encodings, y_test)\n",
    "    \n",
    "    # 2. Load the pre-trained model for sequence classification (binary classification here: num_labels=2)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=2)\n",
    "    \n",
    "    # 3. Set up training arguments with directories specific to this model\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=os.path.join(base_dir, 'results', model_name),\n",
    "        num_train_epochs=3,\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=64,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        logging_dir=os.path.join(base_dir, 'logs', model_name),\n",
    "        logging_steps=10,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"f1\"\n",
    "    )\n",
    "    \n",
    "    # 4. Initialize the Trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=test_dataset,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "    \n",
    "    # 5. Train the model and evaluate\n",
    "    trainer.train()\n",
    "    metrics = trainer.evaluate()\n",
    "    print(f\"Metrics for {model_name}: {metrics}\")\n",
    "    \n",
    "    results_dict[model_name] = metrics\n",
    "\n",
    "# Print final comparison of all models\n",
    "print(\"\\nFinal comparison of models:\")\n",
    "for model_name, metrics in results_dict.items():\n",
    "    print(f\"{model_name}: {metrics}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66826a29-9a09-4858-84a4-3c65400e25dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915e61fd-d4ae-4186-9c0a-ec62609303e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365700b3-abef-43af-aa78-e389a48c361f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d70a92-69c5-4463-8d2d-5a9abae95434",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "472bcf92-2836-4152-a1f7-5d7ac7bd1606",
   "metadata": {},
   "source": [
    "<h1> Dataset related texts prediction </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9152bf4e-39a7-4824-9d3b-be96badec913",
   "metadata": {},
   "source": [
    "single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51dc907a-3ec1-444d-b3fd-063abbf8d669",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f0be705b-e6c3-4e0f-87b2-fbda246b4bc3",
   "metadata": {},
   "source": [
    "Multiple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c896d188-594a-4b36-be83-0f254565e304",
   "metadata": {},
   "source": [
    "<h1> AI GENERATED </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63846c00-49ab-4bdb-9c55-5cef6ee0c045",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (llm_kernel)",
   "language": "python",
   "name": "llm_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
